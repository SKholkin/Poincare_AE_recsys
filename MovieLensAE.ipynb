{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livelossplot in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (0.5.5)\n",
      "Requirement already satisfied: matplotlib in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from livelossplot) (3.6.3)\n",
      "Requirement already satisfied: bokeh in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from livelossplot) (3.1.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (9.4.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (6.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: contourpy>=1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (1.0.7)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (23.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (2023.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from bokeh->livelossplot) (1.23.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from matplotlib->livelossplot) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/skholkin/projects/python_venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pyplot\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MSEloss_with_Mask(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MSEloss_with_Mask,self).__init__()\n",
    "\n",
    "  def forward(self,inputs, targets):\n",
    "    # Masking into a vector of 1's and 0's.\n",
    "    mask = (targets!=0)\n",
    "    mask = mask.float()\n",
    "\n",
    "    # Actual number of ratings.\n",
    "    # Take max to avoid division by zero while calculating loss.\n",
    "    other = torch.Tensor([1.0])\n",
    "    number_ratings = torch.max(torch.sum(mask),other)\n",
    "    error = torch.sum(torch.mul(mask,torch.mul((targets-inputs),(targets-inputs))))\n",
    "    loss = error.div(number_ratings)\n",
    "    return loss[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_file, transform=None):\n",
    "        self.data = pd.read_csv(test_file)\n",
    "        self.data = self.data.iloc[:,1:]\n",
    "        self.transform = transform\n",
    "        \n",
    "        if transform is not None:\n",
    "            self.data = self.transform(np.array(self.data))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        user_vector = self.data.data[0][ind]\n",
    "        \n",
    "        return user_vector\n",
    "    \n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, train_file, transform=None):\n",
    "        self.data = pd.read_csv(train_file)\n",
    "        self.data = self.data.iloc[:,1:]\n",
    "        self.transform = transform\n",
    "        \n",
    "        if transform is not None:\n",
    "            self.data = self.transform(np.array(self.data))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        user_vector = self.data.data[0][ind]\n",
    "        \n",
    "        return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Length:  6039\n",
      "6th User Ratings:  tensor([4., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "train_dat = TrainDataset('train_1m.csv', transformations)\n",
    "\n",
    "print(\"Training Length: \", train_dat.__len__())\n",
    "print(\"6th User Ratings: \", train_dat.__getitem__(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Length:  6039\n",
      "6th User Ratings:  tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_dat = TestDataset('test_1m.csv', transformations)\n",
    "print(\"Testing Length: \", test_dat.__len__())\n",
    "print(\"6th User Ratings: \", test_dat.__getitem__(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(dataset=train_dat, batch_size = batch_size, shuffle=False, num_workers = 1)\n",
    "\n",
    "test_dl = DataLoader(dataset=test_dat, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skholkin/projects/python_venv/lib/python3.10/site-packages/flax/core/frozen_dict.py:169: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "\n",
    "import optax\n",
    "\n",
    "import flax\n",
    "import numpy as np\n",
    "from flax import struct \n",
    "from clu import metrics\n",
    "from dataclasses import field\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "from flax import struct  \n",
    "\n",
    "from clu import metrics\n",
    "\n",
    "from chex import Array\n",
    "from flax import linen as nn\n",
    "from flax.linen.activation import sigmoid, tanh\n",
    "from flax.linen.dtypes import promote_dtype\n",
    "from flax.linen.initializers import orthogonal\n",
    "from flax.linen.linear import default_kernel_init\n",
    "from jax import numpy as jnp\n",
    "from jax import random, vmap\n",
    "from chex import Array\n",
    "from jax import lax\n",
    "from jax.nn.initializers import Initializer as Initializer\n",
    "from jax._src import dtypes\n",
    "\n",
    "from flax.training import train_state\n",
    "\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "  loss: metrics.Average.from_output('loss')\n",
    "    \n",
    "class TrainState(train_state.TrainState):\n",
    "  metrics: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                SimpleAE Summary                                \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams           \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ SimpleAE │ \u001b[2mfloat32\u001b[0m[64,3701] │ \u001b[2mfloat32\u001b[0m[64,3701] │ Dense_0:          │\n",
      "│         │          │                  │                  │   bias:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512]      │\n",
      "│         │          │                  │                  │   kernel:         │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[3701,512] │\n",
      "│         │          │                  │                  │ Dense_1:          │\n",
      "│         │          │                  │                  │   bias:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │          │                  │                  │   kernel:         │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512,256]  │\n",
      "│         │          │                  │                  │ Dense_2:          │\n",
      "│         │          │                  │                  │   bias:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512]      │\n",
      "│         │          │                  │                  │   kernel:         │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[256,512]  │\n",
      "│         │          │                  │                  │ Dense_3:          │\n",
      "│         │          │                  │                  │   bias:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[3701]     │\n",
      "│         │          │                  │                  │   kernel:         │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512,3701] │\n",
      "│         │          │                  │                  │                   │\n",
      "│         │          │                  │                  │ \u001b[1m4,056,949 \u001b[0m\u001b[1;2m(16.2 \u001b[0m  │\n",
      "│         │          │                  │                  │ \u001b[1;2mMB)\u001b[0m               │\n",
      "├─────────┼──────────┼──────────────────┼──────────────────┼───────────────────┤\n",
      "│ Dense_0 │ Dense    │ \u001b[2mfloat32\u001b[0m[64,3701] │ \u001b[2mfloat32\u001b[0m[64,512]  │ bias:             │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512]      │\n",
      "│         │          │                  │                  │ kernel:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[3701,512] │\n",
      "│         │          │                  │                  │                   │\n",
      "│         │          │                  │                  │ \u001b[1m1,895,424 \u001b[0m\u001b[1;2m(7.6 \u001b[0m   │\n",
      "│         │          │                  │                  │ \u001b[1;2mMB)\u001b[0m               │\n",
      "├─────────┼──────────┼──────────────────┼──────────────────┼───────────────────┤\n",
      "│ Dense_1 │ Dense    │ \u001b[2mfloat32\u001b[0m[64,512]  │ \u001b[2mfloat32\u001b[0m[64,256]  │ bias:             │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │          │                  │                  │ kernel:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512,256]  │\n",
      "│         │          │                  │                  │                   │\n",
      "│         │          │                  │                  │ \u001b[1m131,328 \u001b[0m\u001b[1;2m(525.3 \u001b[0m   │\n",
      "│         │          │                  │                  │ \u001b[1;2mKB)\u001b[0m               │\n",
      "├─────────┼──────────┼──────────────────┼──────────────────┼───────────────────┤\n",
      "│ Dense_2 │ Dense    │ \u001b[2mfloat32\u001b[0m[64,256]  │ \u001b[2mfloat32\u001b[0m[64,512]  │ bias:             │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512]      │\n",
      "│         │          │                  │                  │ kernel:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[256,512]  │\n",
      "│         │          │                  │                  │                   │\n",
      "│         │          │                  │                  │ \u001b[1m131,584 \u001b[0m\u001b[1;2m(526.3 \u001b[0m   │\n",
      "│         │          │                  │                  │ \u001b[1;2mKB)\u001b[0m               │\n",
      "├─────────┼──────────┼──────────────────┼──────────────────┼───────────────────┤\n",
      "│ Dense_3 │ Dense    │ \u001b[2mfloat32\u001b[0m[64,512]  │ \u001b[2mfloat32\u001b[0m[64,3701] │ bias:             │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[3701]     │\n",
      "│         │          │                  │                  │ kernel:           │\n",
      "│         │          │                  │                  │ \u001b[2mfloat32\u001b[0m[512,3701] │\n",
      "│         │          │                  │                  │                   │\n",
      "│         │          │                  │                  │ \u001b[1m1,898,613 \u001b[0m\u001b[1;2m(7.6 \u001b[0m   │\n",
      "│         │          │                  │                  │ \u001b[1;2mMB)\u001b[0m               │\n",
      "├─────────┼──────────┼──────────────────┼──────────────────┼───────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m8,113,898 \u001b[0m\u001b[1;2m(32.5 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m         \u001b[0m│\u001b[1m          \u001b[0m│\u001b[1m                  \u001b[0m│\u001b[1m                  \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mMB)\u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴──────────┴──────────────────┴──────────────────┴───────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                     Total Parameters: 8,113,898 \u001b[0m\u001b[1;2m(32.5 MB)\u001b[0m\u001b[1m                      \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dim = next(iter(train_dl)).shape[1]\n",
    "\n",
    "hidden_dim = 1000\n",
    "\n",
    "layer_sizes = [3701, 512, 256]\n",
    "\n",
    "class SimpleAE(nn.Module):\n",
    "    \n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Dense(layer_sizes[1])(x)\n",
    "    x = nn.selu(x)\n",
    "    x = nn.Dense(layer_sizes[2])(x)\n",
    "    x = nn.selu(x)\n",
    "    x = nn.Dense(layer_sizes[1])(x)\n",
    "    x = nn.selu(x)\n",
    "    x = nn.Dense(layer_sizes[0])(x)\n",
    "    return x\n",
    "\n",
    "autoencoder = SimpleAE()\n",
    "print(autoencoder.tabulate(jax.random.PRNGKey(42), jnp.ones((batch_size, dim))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_state(module, rng, learning_rate):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  params = module.init(rng, jnp.ones([batch_size, dim]))['params'] # initialize parameters by passing a template image\n",
    "  tx = optax.sgd(learning_rate)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "\n",
    "train_state = create_train_state(autoencoder, jax.random.PRNGKey(43), 1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MSEMasked(inputs, targets): # Masking into a vector of 1's and 0's.\n",
    "    mask = (targets!=0)\n",
    "    mask = jnp.float32(mask)\n",
    "\n",
    "    # Actual number of ratings.\n",
    "    # Take max to avoid division by zero while calculating loss.\n",
    "    other = jnp.array(1.0)\n",
    "    number_ratings = jnp.maximum(jnp.sum(mask), other)\n",
    "    error = jnp.sum(mask * (targets - inputs) ** 2)\n",
    "    loss = error / number_ratings\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "\n",
    "  def loss_fn(params):\n",
    "    x_rec = state.apply_fn({'params': params}, batch)\n",
    "    loss = MSEMasked(batch, x_rec)\n",
    "    return loss\n",
    "\n",
    "  grad_fn = jax.grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n",
    "\n",
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    x_rec = state.apply_fn({'params': state.params}, batch)\n",
    "    loss = ((x_rec - batch) ** 2).mean()\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state\n",
    "\n",
    "@jax.jit\n",
    "def predict(state, batch):\n",
    "    x_rec = state.apply_fn({'params': state.params}, batch)\n",
    "    return x_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.2523139, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample_batch = jnp.array(next(iter(train_dl)))\n",
    "\n",
    "train_step(train_state, sample_batch)\n",
    "\n",
    "train_state = compute_metrics(state=train_state, batch=sample_batch)\n",
    "train_state.metrics.compute()['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter 94 Metrics: 1.2654837369918823\n",
      "Epoch: 1 Iter 94 Metrics: 1.2492533922195435\n",
      "Epoch: 2 Iter 94 Metrics: 1.231633186340332\n",
      "Epoch: 3 Iter 94 Metrics: 1.2188681364059448\n",
      "Epoch: 4 Iter 94 Metrics: 1.2087388038635254\n",
      "Epoch: 5 Iter 94 Metrics: 1.200228214263916\n",
      "Epoch: 6 Iter 94 Metrics: 1.192807674407959\n",
      "Epoch: 7 Iter 94 Metrics: 1.1861687898635864\n",
      "Epoch: 8 Iter 94 Metrics: 1.180118441581726\n",
      "Epoch: 9 Iter 94 Metrics: 1.1745266914367676\n",
      "Epoch: 10 Iter 94 Metrics: 1.1693040132522583\n",
      "Epoch: 11 Iter 94 Metrics: 1.1643840074539185\n",
      "Epoch: 12 Iter 94 Metrics: 1.1597177982330322\n",
      "Epoch: 13 Iter 94 Metrics: 1.1552667617797852\n",
      "Epoch: 14 Iter 94 Metrics: 1.1510013341903687\n",
      "Epoch: 15 Iter 94 Metrics: 1.1468963623046875\n",
      "Epoch: 16 Iter 94 Metrics: 1.1429322957992554\n",
      "Epoch: 17 Iter 94 Metrics: 1.1390928030014038\n",
      "Epoch: 18 Iter 94 Metrics: 1.1353641748428345\n",
      "Epoch: 19 Iter 94 Metrics: 1.1317347288131714\n",
      "Epoch: 20 Iter 94 Metrics: 1.128193736076355\n",
      "Epoch: 21 Iter 94 Metrics: 1.1247330904006958\n",
      "Epoch: 22 Iter 94 Metrics: 1.1213457584381104\n",
      "Epoch: 23 Iter 94 Metrics: 1.1180245876312256\n",
      "Epoch: 24 Iter 94 Metrics: 1.1147644519805908\n",
      "Epoch: 25 Iter 94 Metrics: 1.1115591526031494\n",
      "Epoch: 26 Iter 94 Metrics: 1.1084043979644775\n",
      "Epoch: 27 Iter 94 Metrics: 1.1052956581115723\n",
      "Epoch: 28 Iter 94 Metrics: 1.102230191230774\n",
      "Epoch: 29 Iter 94 Metrics: 1.0992045402526855\n",
      "Epoch: 30 Iter 94 Metrics: 1.0962162017822266\n",
      "Epoch: 31 Iter 94 Metrics: 1.0932621955871582\n",
      "Epoch: 32 Iter 94 Metrics: 1.0903401374816895\n",
      "Epoch: 33 Iter 94 Metrics: 1.0874481201171875\n",
      "Epoch: 34 Iter 94 Metrics: 1.0845847129821777\n",
      "Epoch: 35 Iter 94 Metrics: 1.0817480087280273\n",
      "Epoch: 36 Iter 94 Metrics: 1.078936219215393\n",
      "Epoch: 37 Iter 94 Metrics: 1.0761481523513794\n",
      "Epoch: 38 Iter 94 Metrics: 1.0733829736709595\n",
      "Epoch: 39 Iter 94 Metrics: 1.0706391334533691\n",
      "Epoch: 40 Iter 94 Metrics: 1.0679161548614502\n",
      "Epoch: 41 Iter 94 Metrics: 1.065212607383728\n",
      "Epoch: 42 Iter 94 Metrics: 1.062528371810913\n",
      "Epoch: 43 Iter 94 Metrics: 1.059862494468689\n",
      "Epoch: 44 Iter 94 Metrics: 1.057214379310608\n",
      "Epoch: 45 Iter 94 Metrics: 1.054583191871643\n",
      "Epoch: 46 Iter 94 Metrics: 1.0519686937332153\n",
      "Epoch: 47 Iter 94 Metrics: 1.049370527267456\n",
      "Epoch: 48 Iter 94 Metrics: 1.0467883348464966\n",
      "Epoch: 49 Iter 94 Metrics: 1.044222116470337\n",
      "Epoch: 50 Iter 94 Metrics: 1.0416712760925293\n",
      "Epoch: 51 Iter 94 Metrics: 1.0391355752944946\n",
      "Epoch: 52 Iter 94 Metrics: 1.0366148948669434\n",
      "Epoch: 53 Iter 94 Metrics: 1.0341094732284546\n",
      "Epoch: 54 Iter 94 Metrics: 1.0316184759140015\n",
      "Epoch: 55 Iter 94 Metrics: 1.0291422605514526\n",
      "Epoch: 56 Iter 94 Metrics: 1.0266807079315186\n",
      "Epoch: 57 Iter 94 Metrics: 1.0242335796356201\n",
      "Epoch: 58 Iter 94 Metrics: 1.021801233291626\n",
      "Epoch: 59 Iter 94 Metrics: 1.019383430480957\n",
      "Epoch: 60 Iter 94 Metrics: 1.0169798135757446\n",
      "Epoch: 61 Iter 94 Metrics: 1.014590859413147\n",
      "Epoch: 62 Iter 94 Metrics: 1.0122164487838745\n",
      "Epoch: 63 Iter 94 Metrics: 1.0098570585250854\n",
      "Epoch: 64 Iter 94 Metrics: 1.0075122117996216\n",
      "Epoch: 65 Iter 94 Metrics: 1.0051817893981934\n",
      "Epoch: 66 Iter 94 Metrics: 1.0028657913208008\n",
      "Epoch: 67 Iter 94 Metrics: 1.0005643367767334\n",
      "Epoch: 68 Iter 94 Metrics: 0.9982775449752808\n",
      "Epoch: 69 Iter 94 Metrics: 0.9960053563117981\n",
      "Epoch: 70 Iter 94 Metrics: 0.9937475323677063\n",
      "Epoch: 71 Iter 94 Metrics: 0.991504967212677\n",
      "Epoch: 72 Iter 94 Metrics: 0.9892773032188416\n",
      "Epoch: 73 Iter 94 Metrics: 0.9870643019676208\n",
      "Epoch: 74 Iter 94 Metrics: 0.984866201877594\n",
      "Epoch: 75 Iter 94 Metrics: 0.9826828241348267\n",
      "Epoch: 76 Iter 94 Metrics: 0.9805145859718323\n",
      "Epoch: 77 Iter 94 Metrics: 0.9783613085746765\n",
      "Epoch: 78 Iter 94 Metrics: 0.9762229919433594\n",
      "Epoch: 79 Iter 94 Metrics: 0.9740994572639465\n",
      "Epoch: 80 Iter 94 Metrics: 0.9719910621643066\n",
      "Epoch: 81 Iter 94 Metrics: 0.969897985458374\n",
      "Epoch: 82 Iter 94 Metrics: 0.9678200483322144\n",
      "Epoch: 83 Iter 94 Metrics: 0.9657572507858276\n",
      "Epoch: 84 Iter 94 Metrics: 0.9637089967727661\n",
      "Epoch: 85 Iter 94 Metrics: 0.9616758823394775\n",
      "Epoch: 86 Iter 94 Metrics: 0.9596579074859619\n",
      "Epoch: 87 Iter 94 Metrics: 0.9576546549797058\n",
      "Epoch: 88 Iter 94 Metrics: 0.9556663632392883\n",
      "Epoch: 89 Iter 94 Metrics: 0.9536928534507751\n",
      "Epoch: 90 Iter 94 Metrics: 0.9517340660095215\n",
      "Epoch: 91 Iter 94 Metrics: 0.9497899413108826\n",
      "Epoch: 92 Iter 94 Metrics: 0.947860598564148\n",
      "Epoch: 93 Iter 94 Metrics: 0.9459460973739624\n",
      "Epoch: 94 Iter 94 Metrics: 0.9440459609031677\n",
      "Epoch: 95 Iter 94 Metrics: 0.9421600699424744\n",
      "Epoch: 96 Iter 94 Metrics: 0.9402886033058167\n",
      "Epoch: 97 Iter 94 Metrics: 0.9384316205978394\n",
      "Epoch: 98 Iter 94 Metrics: 0.9365888237953186\n",
      "Epoch: 99 Iter 94 Metrics: 0.9347602128982544\n",
      "Epoch: 100 Iter 94 Metrics: 0.9329450726509094\n",
      "Epoch: 101 Iter 94 Metrics: 0.9311440587043762\n",
      "Epoch: 102 Iter 94 Metrics: 0.9293568134307861\n",
      "Epoch: 103 Iter 94 Metrics: 0.927582859992981\n",
      "Epoch: 104 Iter 94 Metrics: 0.9258226752281189\n",
      "Epoch: 105 Iter 94 Metrics: 0.9240760207176208\n",
      "Epoch: 106 Iter 94 Metrics: 0.922342836856842\n",
      "Epoch: 107 Iter 94 Metrics: 0.920622706413269\n",
      "Epoch: 108 Iter 94 Metrics: 0.9189158082008362\n",
      "Epoch: 109 Iter 94 Metrics: 0.9172219038009644\n",
      "Epoch: 110 Iter 94 Metrics: 0.9155409336090088\n",
      "Epoch: 111 Iter 94 Metrics: 0.9138728380203247\n",
      "Epoch: 112 Iter 94 Metrics: 0.9122170805931091\n",
      "Epoch: 113 Iter 94 Metrics: 0.9105738997459412\n",
      "Epoch: 114 Iter 94 Metrics: 0.9089427590370178\n",
      "Epoch: 115 Iter 94 Metrics: 0.9073240756988525\n",
      "Epoch: 116 Iter 94 Metrics: 0.9057179093360901\n",
      "Epoch: 117 Iter 94 Metrics: 0.9041229486465454\n",
      "Epoch: 118 Iter 94 Metrics: 0.9025402069091797\n",
      "Epoch: 119 Iter 94 Metrics: 0.9009694457054138\n",
      "Epoch: 120 Iter 94 Metrics: 0.8994104266166687\n",
      "Epoch: 121 Iter 94 Metrics: 0.8978630304336548\n",
      "Epoch: 122 Iter 94 Metrics: 0.8963268995285034\n",
      "Epoch: 123 Iter 94 Metrics: 0.894801914691925\n",
      "Epoch: 124 Iter 94 Metrics: 0.893288254737854\n",
      "Epoch: 125 Iter 94 Metrics: 0.8917858600616455\n",
      "Epoch: 126 Iter 94 Metrics: 0.8902943134307861\n",
      "Epoch: 127 Iter 94 Metrics: 0.8888137340545654\n",
      "Epoch: 128 Iter 94 Metrics: 0.88734370470047\n",
      "Epoch: 129 Iter 94 Metrics: 0.8858848810195923\n",
      "Epoch: 130 Iter 94 Metrics: 0.8844363689422607\n",
      "Epoch: 131 Iter 94 Metrics: 0.882998526096344\n",
      "Epoch: 132 Iter 94 Metrics: 0.8815706968307495\n",
      "Epoch: 133 Iter 94 Metrics: 0.880153477191925\n",
      "Epoch: 134 Iter 94 Metrics: 0.8787461519241333\n",
      "Epoch: 135 Iter 94 Metrics: 0.877348780632019\n",
      "Epoch: 136 Iter 94 Metrics: 0.8759616613388062\n",
      "Epoch: 137 Iter 94 Metrics: 0.8745842576026917\n",
      "Epoch: 138 Iter 94 Metrics: 0.8732166290283203\n",
      "Epoch: 139 Iter 94 Metrics: 0.8718588352203369\n",
      "Epoch: 140 Iter 94 Metrics: 0.8705103993415833\n",
      "Epoch: 141 Iter 94 Metrics: 0.8691713213920593\n",
      "Epoch: 142 Iter 94 Metrics: 0.867841899394989\n",
      "Epoch: 143 Iter 94 Metrics: 0.8665220737457275\n",
      "Epoch: 144 Iter 94 Metrics: 0.865210771560669\n",
      "Epoch: 145 Iter 94 Metrics: 0.8639088869094849\n",
      "Epoch: 146 Iter 94 Metrics: 0.8626161813735962\n",
      "Epoch: 147 Iter 94 Metrics: 0.8613321781158447\n",
      "Epoch: 148 Iter 94 Metrics: 0.8600568771362305\n",
      "Epoch: 149 Iter 94 Metrics: 0.8587905168533325\n",
      "Epoch: 150 Iter 94 Metrics: 0.8575325608253479\n",
      "Epoch: 151 Iter 94 Metrics: 0.85628342628479\n",
      "Epoch: 152 Iter 94 Metrics: 0.855042576789856\n",
      "Epoch: 153 Iter 94 Metrics: 0.8538098931312561\n",
      "Epoch: 154 Iter 94 Metrics: 0.8525857329368591\n",
      "Epoch: 155 Iter 94 Metrics: 0.8513697981834412\n",
      "Epoch: 156 Iter 94 Metrics: 0.8501617908477783\n",
      "Epoch: 157 Iter 94 Metrics: 0.8489616513252258\n",
      "Epoch: 158 Iter 94 Metrics: 0.8477694988250732\n",
      "Epoch: 159 Iter 94 Metrics: 0.8465854525566101\n",
      "Epoch: 160 Iter 94 Metrics: 0.8454088568687439\n",
      "Epoch: 161 Iter 94 Metrics: 0.8442400693893433\n",
      "Epoch: 162 Iter 94 Metrics: 0.8430789113044739\n",
      "Epoch: 163 Iter 94 Metrics: 0.8419253826141357\n",
      "Epoch: 164 Iter 94 Metrics: 0.8407793045043945\n",
      "Epoch: 165 Iter 94 Metrics: 0.8396404385566711\n",
      "Epoch: 166 Iter 94 Metrics: 0.8385085463523865\n",
      "Epoch: 167 Iter 94 Metrics: 0.8373839259147644\n",
      "Epoch: 168 Iter 94 Metrics: 0.8362664580345154\n",
      "Epoch: 169 Iter 94 Metrics: 0.8351560235023499\n",
      "Epoch: 170 Iter 94 Metrics: 0.8340529203414917\n",
      "Epoch: 171 Iter 94 Metrics: 0.8329566717147827\n",
      "Epoch: 172 Iter 94 Metrics: 0.8318671584129333\n",
      "Epoch: 173 Iter 94 Metrics: 0.830784261226654\n",
      "Epoch: 174 Iter 94 Metrics: 0.8297080993652344\n",
      "Epoch: 175 Iter 94 Metrics: 0.8286385536193848\n",
      "Epoch: 176 Iter 94 Metrics: 0.8275755643844604\n",
      "Epoch: 177 Iter 94 Metrics: 0.8265190124511719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 178 Iter 94 Metrics: 0.8254687190055847\n",
      "Epoch: 179 Iter 94 Metrics: 0.824424684047699\n",
      "Epoch: 180 Iter 94 Metrics: 0.8233870267868042\n",
      "Epoch: 181 Iter 94 Metrics: 0.8223552703857422\n",
      "Epoch: 182 Iter 94 Metrics: 0.8213297128677368\n",
      "Epoch: 183 Iter 94 Metrics: 0.820310115814209\n",
      "Epoch: 184 Iter 94 Metrics: 0.8192968368530273\n",
      "Epoch: 185 Iter 94 Metrics: 0.8182895183563232\n",
      "Epoch: 186 Iter 94 Metrics: 0.8172877430915833\n",
      "Epoch: 187 Iter 94 Metrics: 0.8162919282913208\n",
      "Epoch: 188 Iter 94 Metrics: 0.8153018951416016\n",
      "Epoch: 189 Iter 94 Metrics: 0.8143177628517151\n",
      "Epoch: 190 Iter 94 Metrics: 0.8133392930030823\n",
      "Epoch: 191 Iter 94 Metrics: 0.8123665452003479\n",
      "Epoch: 192 Iter 94 Metrics: 0.8113994598388672\n",
      "Epoch: 193 Iter 94 Metrics: 0.8104376792907715\n",
      "Epoch: 194 Iter 94 Metrics: 0.8094813823699951\n",
      "Epoch: 195 Iter 94 Metrics: 0.8085306882858276\n",
      "Epoch: 196 Iter 94 Metrics: 0.8075851202011108\n",
      "Epoch: 197 Iter 94 Metrics: 0.806644856929779\n",
      "Epoch: 198 Iter 94 Metrics: 0.8057100176811218\n",
      "Epoch: 199 Iter 94 Metrics: 0.8047805428504944\n",
      "Epoch: 200 Iter 94 Metrics: 0.8038563132286072\n",
      "Epoch: 201 Iter 94 Metrics: 0.8029373288154602\n",
      "Epoch: 202 Iter 94 Metrics: 0.8020234107971191\n",
      "Epoch: 203 Iter 94 Metrics: 0.8011143803596497\n",
      "Epoch: 204 Iter 94 Metrics: 0.8002105951309204\n",
      "Epoch: 205 Iter 94 Metrics: 0.7993117570877075\n",
      "Epoch: 206 Iter 94 Metrics: 0.7984178066253662\n",
      "Epoch: 207 Iter 94 Metrics: 0.7975288033485413\n",
      "Epoch: 208 Iter 94 Metrics: 0.7966448068618774\n",
      "Epoch: 209 Iter 94 Metrics: 0.7957654595375061\n",
      "Epoch: 210 Iter 94 Metrics: 0.7948910593986511\n",
      "Epoch: 211 Iter 94 Metrics: 0.7940215468406677\n",
      "Epoch: 212 Iter 94 Metrics: 0.7931566834449768\n",
      "Epoch: 213 Iter 94 Metrics: 0.7922965884208679\n",
      "Epoch: 214 Iter 94 Metrics: 0.7914408445358276\n",
      "Epoch: 215 Iter 94 Metrics: 0.7905897498130798\n",
      "Epoch: 216 Iter 94 Metrics: 0.7897432446479797\n",
      "Epoch: 217 Iter 94 Metrics: 0.7889014482498169\n",
      "Epoch: 218 Iter 94 Metrics: 0.7880640625953674\n",
      "Epoch: 219 Iter 94 Metrics: 0.7872311472892761\n",
      "Epoch: 220 Iter 94 Metrics: 0.7864027619361877\n",
      "Epoch: 221 Iter 94 Metrics: 0.7855790257453918\n",
      "Epoch: 222 Iter 94 Metrics: 0.7847588062286377\n",
      "Epoch: 223 Iter 94 Metrics: 0.7839431166648865\n",
      "Epoch: 224 Iter 94 Metrics: 0.7831318378448486\n",
      "Epoch: 225 Iter 94 Metrics: 0.7823247313499451\n",
      "Epoch: 226 Iter 94 Metrics: 0.781522274017334\n",
      "Epoch: 227 Iter 94 Metrics: 0.7807236909866333\n",
      "Epoch: 228 Iter 94 Metrics: 0.7799291014671326\n",
      "Epoch: 229 Iter 94 Metrics: 0.7791390419006348\n",
      "Epoch: 230 Iter 94 Metrics: 0.7783529758453369\n",
      "Epoch: 231 Iter 94 Metrics: 0.7775708436965942\n",
      "Epoch: 232 Iter 94 Metrics: 0.7767927050590515\n",
      "Epoch: 233 Iter 94 Metrics: 0.7760186791419983\n",
      "Epoch: 234 Iter 94 Metrics: 0.7752485275268555\n",
      "Epoch: 235 Iter 94 Metrics: 0.774482011795044\n",
      "Epoch: 236 Iter 94 Metrics: 0.7737197279930115\n",
      "Epoch: 237 Iter 94 Metrics: 0.7729613184928894\n",
      "Epoch: 238 Iter 94 Metrics: 0.7722064852714539\n",
      "Epoch: 239 Iter 94 Metrics: 0.7714555263519287\n",
      "Epoch: 240 Iter 94 Metrics: 0.770708441734314\n",
      "Epoch: 241 Iter 94 Metrics: 0.7699649333953857\n",
      "Epoch: 242 Iter 94 Metrics: 0.7692253589630127\n",
      "Epoch: 243 Iter 94 Metrics: 0.7684893608093262\n",
      "Epoch: 244 Iter 94 Metrics: 0.7677570581436157\n",
      "Epoch: 245 Iter 94 Metrics: 0.7670286893844604\n",
      "Epoch: 246 Iter 94 Metrics: 0.7663032412528992\n",
      "Epoch: 247 Iter 94 Metrics: 0.7655816674232483\n",
      "Epoch: 248 Iter 94 Metrics: 0.7648638486862183\n",
      "Epoch: 249 Iter 94 Metrics: 0.7641491889953613\n",
      "Epoch: 250 Iter 94 Metrics: 0.7634378671646118\n",
      "Epoch: 251 Iter 94 Metrics: 0.7627305388450623\n",
      "Epoch: 252 Iter 94 Metrics: 0.7620261907577515\n",
      "Epoch: 253 Iter 94 Metrics: 0.7613252401351929\n",
      "Epoch: 254 Iter 94 Metrics: 0.760627806186676\n",
      "Epoch: 255 Iter 94 Metrics: 0.7599336504936218\n",
      "Epoch: 256 Iter 94 Metrics: 0.759242832660675\n",
      "Epoch: 257 Iter 94 Metrics: 0.7585554122924805\n",
      "Epoch: 258 Iter 94 Metrics: 0.7578713893890381\n",
      "Epoch: 259 Iter 94 Metrics: 0.7571902275085449\n",
      "Epoch: 260 Iter 94 Metrics: 0.7565122246742249\n",
      "Epoch: 261 Iter 94 Metrics: 0.7558377385139465\n",
      "Epoch: 262 Iter 94 Metrics: 0.7551663517951965\n",
      "Epoch: 263 Iter 94 Metrics: 0.7544980645179749\n",
      "Epoch: 264 Iter 94 Metrics: 0.7538329362869263\n",
      "Epoch: 265 Iter 94 Metrics: 0.7531709671020508\n",
      "Epoch: 266 Iter 94 Metrics: 0.7525120973587036\n",
      "Epoch: 267 Iter 94 Metrics: 0.7518564462661743\n",
      "Epoch: 268 Iter 94 Metrics: 0.7512037754058838\n",
      "Epoch: 269 Iter 94 Metrics: 0.7505538463592529\n",
      "Epoch: 270 Iter 94 Metrics: 0.7499068975448608\n",
      "Epoch: 271 Iter 94 Metrics: 0.7492631673812866\n",
      "Epoch: 272 Iter 94 Metrics: 0.7486222386360168\n",
      "Epoch: 273 Iter 94 Metrics: 0.7479842901229858\n",
      "Epoch: 274 Iter 94 Metrics: 0.747349202632904\n",
      "Epoch: 275 Iter 94 Metrics: 0.7467169761657715\n",
      "Epoch: 276 Iter 94 Metrics: 0.7460876703262329\n",
      "Epoch: 277 Iter 94 Metrics: 0.7454613447189331\n",
      "Epoch: 278 Iter 94 Metrics: 0.7448375225067139\n",
      "Epoch: 279 Iter 94 Metrics: 0.7442166209220886\n",
      "Epoch: 280 Iter 94 Metrics: 0.7435985803604126\n",
      "Epoch: 281 Iter 94 Metrics: 0.7429832220077515\n",
      "Epoch: 282 Iter 94 Metrics: 0.7423703074455261\n",
      "Epoch: 283 Iter 94 Metrics: 0.7417604327201843\n",
      "Epoch: 284 Iter 94 Metrics: 0.7411531209945679\n",
      "Epoch: 285 Iter 94 Metrics: 0.7405485510826111\n",
      "Epoch: 286 Iter 94 Metrics: 0.7399464249610901\n",
      "Epoch: 287 Iter 94 Metrics: 0.7393470406532288\n",
      "Epoch: 288 Iter 94 Metrics: 0.7387506365776062\n",
      "Epoch: 289 Iter 94 Metrics: 0.7381568551063538\n",
      "Epoch: 290 Iter 94 Metrics: 0.7375651001930237\n",
      "Epoch: 291 Iter 94 Metrics: 0.7369760870933533\n",
      "Epoch: 292 Iter 94 Metrics: 0.7363895177841187\n",
      "Epoch: 293 Iter 94 Metrics: 0.7358059883117676\n",
      "Epoch: 294 Iter 94 Metrics: 0.735224723815918\n",
      "Epoch: 295 Iter 94 Metrics: 0.734645664691925\n",
      "Epoch: 296 Iter 94 Metrics: 0.7340690493583679\n",
      "Epoch: 297 Iter 94 Metrics: 0.7334950566291809\n",
      "Epoch: 298 Iter 94 Metrics: 0.732923686504364\n",
      "Epoch: 299 Iter 94 Metrics: 0.7323545813560486\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for ep in range(epochs):\n",
    "    ep_loss = []\n",
    "    for i, batch in enumerate(iter(train_dl)):\n",
    "        batch = jnp.array(batch)\n",
    "        train_state = train_step(train_state, batch)\n",
    "        train_state = compute_metrics(state=train_state, batch=batch)\n",
    "        metrics = train_state.metrics.compute()['loss']\n",
    "        ep_loss.append(metrics)\n",
    "    \n",
    "    print(f'Epoch: {ep} Iter {i} Metrics: {jnp.mean(np.array(ep_loss))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299 Iter 94 Metrics: 0.7318029403686523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ep_loss = []\n",
    "for i, batch in enumerate(iter(test_dl)):\n",
    "    batch = jnp.array(batch)\n",
    "    train_state = train_step(train_state, batch)\n",
    "    train_state = compute_metrics(state=train_state, batch=batch)\n",
    "    metrics = train_state.metrics.compute()['loss']\n",
    "    ep_loss.append(metrics)\n",
    "\n",
    "print(f'Epoch: {ep} Iter {i} Metrics: {jnp.mean(np.array(ep_loss))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@50: 0.07524786442144529 HR@10: 0.27906976744186046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_HR_jax(state, train_loader, test_loader, top_n=10):\n",
    "\n",
    "    counter, hits = 0, 0\n",
    "    r = []\n",
    "    for i, (batch_train, batch_val) in enumerate(zip(iter(train_loader), iter(test_loader))):\n",
    "        batch_train, batch_val = jnp.array(batch_train), jnp.array(batch_val)\n",
    "        delta = batch_val - batch_train\n",
    "        x_rec = state.apply_fn({'params': state.params}, batch_train)\n",
    "        \n",
    "        for k in range(delta.shape[0]):\n",
    "            non_zero_ind = np.nonzero(np.array(delta[k]))[0]\n",
    "            if len(non_zero_ind) > 0:\n",
    "                counter += 1\n",
    "                diff = set([int(item) for item  in np.argpartition(np.array(x_rec[k]).reshape(-1), -top_n)[-top_n:]]) - (set([int(item) for item in non_zero_ind]))\n",
    "                \n",
    "                if len(diff) < top_n:\n",
    "                    hits += 1\n",
    "    return hits / counter\n",
    "\n",
    "def get_recall_jax(state, train_loader, test_loader, top_n=50):\n",
    "\n",
    "    counter, hits = 0, 0\n",
    "    r = []\n",
    "    for i, (batch_train, batch_val) in enumerate(zip(iter(train_loader), iter(test_loader))):\n",
    "        batch_train, batch_val = jnp.array(batch_train), jnp.array(batch_val)\n",
    "        delta = batch_val - batch_train\n",
    "        \n",
    "        x_rec = state.apply_fn({'params': state.params}, batch_train)\n",
    "        \n",
    "        for k in range(delta.shape[0]):\n",
    "            non_zero_ind = np.nonzero(np.array(delta[k]))[0]\n",
    "            if len(non_zero_ind) > 0:\n",
    "                counter += 1\n",
    "                diff = set([int(item) for item in  np.argpartition(np.array(x_rec[k]).reshape(-1), -top_n)[-top_n:]]).intersection(set([int(item) for item in non_zero_ind]))\n",
    "                r.append(len(diff) / len(non_zero_ind))\n",
    "                if len(diff) < top_n:\n",
    "                    hits += 1\n",
    "    return np.mean(r)\n",
    "        \n",
    "get_recall_jax(train_state, train_dl, test_dl)\n",
    "\n",
    "print(f'R@50: {get_recall_jax(train_state, train_dl, test_dl, top_n=50)} HR@10: {get_HR_jax(train_state, train_dl, test_dl, top_n=10)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperbolic AE (Unfortunately it is not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_dim, out_dim = 3701, 3701\n",
    "\n",
    "hidden_dim = 256\n",
    "\n",
    "dims = [in_dim, hidden_dim, out_dim]\n",
    "c = -1\n",
    "\n",
    "class PoincareSimpleAE(nn.Module):\n",
    "    \n",
    "    param_dtype = jnp.float32\n",
    "    kernel_init: Callable = default_kernel_init\n",
    "    bias_init: Callable = nn.initializers.uniform(scale= 1 / jnp.sqrt(in_dim))\n",
    "        \n",
    "    in_dim, out_dim = in_dim, out_dim\n",
    "    hidden_dim = hidden_dim\n",
    "    c = c\n",
    "    act = nn.relu\n",
    "    \n",
    "    def setup(self):\n",
    "        self.scalars_1 = self.param(\n",
    "            \"scalars@1\",\n",
    "            self.kernel_init,\n",
    "            (self.hidden_dim, self.in_dim),\n",
    "            self.param_dtype,\n",
    "        )\n",
    "        \n",
    "        self.bias_poincare_1 = self.param(\n",
    "            \"bias_poincare@1\",\n",
    "            self.bias_init,\n",
    "            (self.hidden_dim,),\n",
    "            self.param_dtype,\n",
    "        )\n",
    "        \n",
    "        self.scalars_2 = self.param(\n",
    "            \"scalars@2\",\n",
    "            self.kernel_init,\n",
    "            (self.out_dim, self.hidden_dim),\n",
    "            self.param_dtype,\n",
    "        )\n",
    "    \n",
    "        self.bias_poincare_2 = self.param(\n",
    "            \"bias_poincare@2\",\n",
    "            self.bias_init,\n",
    "            (self.out_dim,),\n",
    "            self.param_dtype,\n",
    "        )\n",
    "        \n",
    "        self.balls = {'bias_poincare@1': PoincareBall(self.hidden_dim, self.c),\n",
    "                      'bias_poincare@2': PoincareBall(self.out_dim, self.c)}\n",
    "        \n",
    "        ball_in = PoincareBall(self.in_dim, self.c)\n",
    "        self.matvec_1 = jax.vmap(ball_in.mobius_matvec, in_axes=(None, 0), out_axes=0)\n",
    "        \n",
    "        ball_hidden = PoincareBall(self.hidden_dim, self.c)\n",
    "        self.add_1 = jax.vmap(ball_hidden.mobius_add, in_axes=(None, 0), out_axes=0)\n",
    "        self.log_hidden = jax.vmap(ball_hidden.log, in_axes=(None, 0), out_axes=0)\n",
    "        self.exp_hidden = jax.vmap(ball_hidden.exp, in_axes=(None, 0), out_axes=0)\n",
    "        \n",
    "        self.matvec_2 = jax.vmap(ball_hidden.mobius_matvec, in_axes=(None, 0), out_axes=0)\n",
    "        ball_out = PoincareBall(self.out_dim, self.c)\n",
    "        self.add_2 = jax.vmap(ball_out.mobius_add, in_axes=(None, 0), out_axes=0)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        Ax = self.matvec_1(self.scalars_1, x)\n",
    "        Ax_b = self.add_1(self.bias_poincare_1, Ax)\n",
    "        \n",
    "        activation_hid = self.log_hidden(jnp.zeros([Ax_b.shape[1]]), Ax_b)\n",
    "        activation_hid = nn.relu(activation_hid)\n",
    "        activation_hid = self.exp_hidden(jnp.zeros([Ax_b.shape[1]]), Ax_b)\n",
    "\n",
    "        output = self.matvec_2(self.scalars_2, activation_hid)\n",
    "        output = self.add_2(self.bias_poincare_2, output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rieoptax.geometry.hyperbolic import PoincareBall\n",
    "\n",
    "from flax.training import train_state\n",
    "class TrainStateRiemannianMLP(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    balls = {'bias_poincare@1': PoincareBall(hidden_dim, c),\n",
    "                  'bias_poincare@2': PoincareBall(out_dim, c)}\n",
    "    \n",
    "    def apply_gradients(self, *, grads, **kwargs):\n",
    "        \"\"\"Updates `step`, `params`, `opt_state` and `**kwargs` in return value.\n",
    "\n",
    "        Note that internally this function calls `.tx.update()` followed by a call\n",
    "        to `optax.apply_updates()` to update `params` and `opt_state`.\n",
    "\n",
    "        Args:\n",
    "          grads: Gradients that have the same pytree structure as `.params`.\n",
    "          **kwargs: Additional dataclass attributes that should be `.replace()`-ed.\n",
    "\n",
    "        Returns:\n",
    "          An updated instance of `self` with `step` incremented by one, `params`\n",
    "          and `opt_state` updated by applying `grads`, and additional attributes\n",
    "          replaced as specified by `kwargs`.\n",
    "        \"\"\"\n",
    "        updates, new_opt_state = self.tx.update(\n",
    "            grads, self.opt_state, self.params)\n",
    "        \n",
    "        \n",
    "        poincare_param_names = self.balls.keys()\n",
    "        r_grad_poincare_bias, old_bias_params = {}, {}\n",
    "        for name in poincare_param_names:\n",
    "            \n",
    "            old_bias_params[name] = self.params[name]\n",
    "            bias_poincare_grads = updates[name]\n",
    "            r_grad_poincare_bias[name] = self.balls[name].egrad_to_rgrad(old_bias_params[name], bias_poincare_grads)\n",
    "        \n",
    "        updates = updates.unfreeze()\n",
    "        for name in poincare_param_names:\n",
    "            updates[name] = r_grad_poincare_bias[name]\n",
    "            \n",
    "        updates = flax.core.frozen_dict.freeze(updates)\n",
    "        \n",
    "        new_params = optax.apply_updates(self.params, updates)\n",
    "        \n",
    "        lr = self.lr\n",
    "        new_params = new_params.unfreeze()\n",
    "        for name in poincare_param_names:\n",
    "            bias_poincare_new = new_params[name]\n",
    "            tv = lr * r_grad_poincare_bias[name]\n",
    "            new_params[name] = self.balls[name].exp(old_bias_params[name], tv)\n",
    "        \n",
    "        new_params = flax.core.frozen_dict.freeze(new_params)\n",
    "        \n",
    "        return self.replace(\n",
    "            step=self.step + 1,\n",
    "            params=new_params,\n",
    "            opt_state=new_opt_state,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_state(module, rng, learning_rate):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  from flax.training import train_state\n",
    "  class TrainState(TrainStateRiemannianMLP):\n",
    "    metrics: Metrics\n",
    "    lr = learning_rate\n",
    "  params = module.init(rng, jnp.ones([batch_size, in_dim]))['params'] # initialize parameters by passing a template image\n",
    "  tx = optax.sgd(learning_rate)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "\n",
    "\n",
    "def MSEMasked(inputs, targets): # Masking into a vector of 1's and 0's.\n",
    "    mask = (targets!=0)\n",
    "    mask = jnp.float32(mask)\n",
    "\n",
    "    # Actual number of ratings.\n",
    "    # Take max to avoid division by zero while calculating loss.\n",
    "    other = jnp.array(1.0)\n",
    "    number_ratings = jnp.maximum(jnp.sum(mask), other)\n",
    "    error = jnp.sum(mask * (targets - inputs) ** 2)\n",
    "    loss = error / number_ratings\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "\n",
    "  def loss_fn(params):\n",
    "    x_rec = state.apply_fn({'params': params}, batch)\n",
    "    loss = MSEMasked(batch, x_rec)\n",
    "    return loss\n",
    "  \n",
    "  grad_fn = jax.grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n",
    "\n",
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    x_rec = state.apply_fn({'params': state.params}, batch)\n",
    "    loss = MSEMasked(batch, x_rec)\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poincare_ae = PoincareSimpleAE()\n",
    "train_state = create_train_state(poincare_ae, jax.random.PRNGKey(42), 1e-03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter 94 Metrics: 0.0004129254666622728\n",
      "Epoch: 1 Iter 94 Metrics: 0.00041290681110695004\n",
      "Epoch: 2 Iter 94 Metrics: 0.00041289953514933586\n",
      "Epoch: 3 Iter 94 Metrics: 0.00041289563523605466\n",
      "Epoch: 4 Iter 94 Metrics: 0.0004128931905142963\n",
      "Epoch: 5 Iter 94 Metrics: 0.0004128915898036212\n",
      "Epoch: 6 Iter 94 Metrics: 0.00041289033833891153\n",
      "Epoch: 7 Iter 94 Metrics: 0.00041288946522399783\n",
      "Epoch: 8 Iter 94 Metrics: 0.00041288885404355824\n",
      "Epoch: 9 Iter 94 Metrics: 0.00041288833017461\n",
      "Epoch: 10 Iter 94 Metrics: 0.00041288789361715317\n",
      "Epoch: 11 Iter 94 Metrics: 0.00041288757347501814\n",
      "Epoch: 12 Iter 94 Metrics: 0.00041288742795586586\n",
      "Epoch: 13 Iter 94 Metrics: 0.0004128873406443745\n",
      "Epoch: 14 Iter 94 Metrics: 0.0004128873406443745\n",
      "Epoch: 15 Iter 94 Metrics: 0.0004128873406443745\n",
      "Epoch: 16 Iter 94 Metrics: 0.0004128872824367136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         batch \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdivide(batch, jnp\u001b[38;5;241m.\u001b[39mexpand_dims(jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(batch, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         print(jnp.linalg.norm(batch, axis=1))\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m         train_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         train_state \u001b[38;5;241m=\u001b[39m compute_metrics(state\u001b[38;5;241m=\u001b[39mtrain_state, batch\u001b[38;5;241m=\u001b[39mbatch)\n\u001b[1;32m     11\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m train_state\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mcompute()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:235\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 235\u001b[0m   outs, out_flat, out_tree, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_params_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable()\n\u001b[1;32m    240\u001b[0m   use_fastpath \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    241\u001b[0m       executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    242\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(executable, pxla\u001b[38;5;241m.\u001b[39mMeshExecutable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, xc\u001b[38;5;241m.\u001b[39mArrayImpl) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out_flat)\n\u001b[1;32m    249\u001b[0m   )\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:184\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m   dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    186\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/core.py:2577\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2573\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2574\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2575\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2576\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/core.py:807\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:1291\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, in_positional_semantics, out_positional_semantics, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m   _allow_propagation_to_outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_shardings)\n\u001b[0;32m-> 1291\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_is_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1295\u001b[0m         _allow_propagation_to_outputs\u001b[38;5;241m=\u001b[39m_allow_propagation_to_outputs)\n\u001b[1;32m   1296\u001b[0m _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:1377\u001b[0m, in \u001b[0;36m_pjit_lower\u001b[0;34m(jaxpr, in_shardings, out_shardings, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(in_shardings, da)\n\u001b[1;32m   1376\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m SameDeviceAssignmentTuple(out_shardings, da)\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pjit_lower_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:1437\u001b[0m, in \u001b[0;36m_pjit_lower_cached\u001b[0;34m(jaxpr, sdat_in_shardings, sdat_out_shardings, resource_env, donated_invars, name, in_is_global, keep_unused, always_lower, lowering_platform)\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mlower_mesh_computation(\n\u001b[1;32m   1432\u001b[0m     jaxpr, api_name, name, mesh,\n\u001b[1;32m   1433\u001b[0m     in_shardings, out_shardings, donated_invars,\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m, jaxpr\u001b[38;5;241m.\u001b[39min_avals, tiling_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, in_is_global\u001b[38;5;241m=\u001b[39min_is_global,\n\u001b[1;32m   1435\u001b[0m     lowering_platform\u001b[38;5;241m=\u001b[39mlowering_platform)\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1437\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_sharding_computation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m      \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_avals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_is_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_is_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1440\u001b[0m \u001b[43m      \u001b[49m\u001b[43malways_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_lower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevices_from_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlowering_platform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlowering_platform\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:3082\u001b[0m, in \u001b[0;36mlower_sharding_computation\u001b[0;34m(fun_or_jaxpr, api_name, fun_name, in_shardings, out_shardings, donated_invars, global_in_avals, in_is_global, keep_unused, always_lower, devices_from_context, lowering_platform)\u001b[0m\n\u001b[1;32m   3080\u001b[0m ordered_effects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(effects\u001b[38;5;241m.\u001b[39mordered_effects\u001b[38;5;241m.\u001b[39mfilter_in(closed_jaxpr\u001b[38;5;241m.\u001b[39meffects))\n\u001b[1;32m   3081\u001b[0m arg_names, result_names \u001b[38;5;241m=\u001b[39m _debug_names(jaxpr\u001b[38;5;241m.\u001b[39mdebug_info, kept_var_idx)\n\u001b[0;32m-> 3082\u001b[0m lowering_result \u001b[38;5;241m=\u001b[39m \u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_jaxpr_to_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosed_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43munordered_effects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordered_effects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Optionally, override the lowering platform\u001b[39;49;00m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlowering_platform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplatform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis_ctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplicated_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplicated_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_op_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_op_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3098\u001b[0m module, keepalive, host_callbacks \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3099\u001b[0m     lowering_result\u001b[38;5;241m.\u001b[39mmodule, lowering_result\u001b[38;5;241m.\u001b[39mkeepalive,\n\u001b[1;32m   3100\u001b[0m     lowering_result\u001b[38;5;241m.\u001b[39mhost_callbacks)\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;66;03m# backend and device_assignment is passed through to MeshExecutable because\u001b[39;00m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;66;03m# if keep_unused=False and all in_shardings are pruned, then there is no way\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;66;03m# to get the device_assignment and backend. So pass it to MeshExecutable\u001b[39;00m\n\u001b[1;32m   3105\u001b[0m \u001b[38;5;66;03m# because we calculate the device_assignment and backend before in_shardings,\u001b[39;00m\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;66;03m# etc are pruned.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:742\u001b[0m, in \u001b[0;36mlower_jaxpr_to_module\u001b[0;34m(module_name, jaxpr, unordered_effects, ordered_effects, backend_or_name, platform, axis_context, name_stack, donated_args, replicated_args, arg_shardings, result_shardings, arg_names, result_names)\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m unlowerable_effects:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot lower jaxpr with unlowerable effects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munlowerable_effects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 742\u001b[0m   \u001b[43mlower_jaxpr_to_fun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpublic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreplace_tokens_with_dummy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreplicated_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplicated_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m      \u001b[49m\u001b[43marg_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_output_aliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_output_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m      \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mverify():\n\u001b[1;32m    752\u001b[0m   module_string \u001b[38;5;241m=\u001b[39m module_to_string(ctx\u001b[38;5;241m.\u001b[39mmodule)\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:1044\u001b[0m, in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(arg)\n\u001b[1;32m   1043\u001b[0m callee_name_stack \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mname_stack\u001b[38;5;241m.\u001b[39mextend(util\u001b[38;5;241m.\u001b[39mwrap_name(name, api_name))\n\u001b[0;32m-> 1044\u001b[0m out_vals, tokens_out \u001b[38;5;241m=\u001b[39m \u001b[43mjaxpr_subcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallee_name_stack\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mir_constants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_var_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_var_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m outs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_tokens:\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:1179\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m   axis_size_env \u001b[38;5;241m=\u001b[39m {d: read(d)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1176\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m avals_in \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mDShapedArray\n\u001b[1;32m   1177\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(d) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mVar}\n\u001b[1;32m   1178\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m-> 1179\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrule_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_unwrap_singleton_ir_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[1;32m   1182\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/pjit.py:1489\u001b[0m, in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, in_positional_semantics, out_positional_semantics, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1483\u001b[0m result_shardings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_unspecified(o) \u001b[38;5;28;01melse\u001b[39;00m o\u001b[38;5;241m.\u001b[39m_to_xla_op_sharding(aval\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m   1484\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m aval, o \u001b[38;5;129;01min\u001b[39;00m safe_zip(ctx\u001b[38;5;241m.\u001b[39mavals_out, out_shardings)]\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;66;03m# TODO(b/228598865): inlined calls cannot have shardings set directly on the\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;66;03m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;66;03m# using_sharding_annotation=False means we add an identity operation instead.\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_jaxpr_to_fun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sharding_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpjit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m tokens_in \u001b[38;5;241m=\u001b[39m [ctx\u001b[38;5;241m.\u001b[39mtokens_in\u001b[38;5;241m.\u001b[39mget(eff) \u001b[38;5;28;01mfor\u001b[39;00m eff \u001b[38;5;129;01min\u001b[39;00m effects]\n\u001b[1;32m   1494\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mctx\u001b[38;5;241m.\u001b[39mdim_var_values, \u001b[38;5;241m*\u001b[39mtokens_in, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:1044\u001b[0m, in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(arg)\n\u001b[1;32m   1043\u001b[0m callee_name_stack \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mname_stack\u001b[38;5;241m.\u001b[39mextend(util\u001b[38;5;241m.\u001b[39mwrap_name(name, api_name))\n\u001b[0;32m-> 1044\u001b[0m out_vals, tokens_out \u001b[38;5;241m=\u001b[39m \u001b[43mjaxpr_subcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallee_name_stack\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mir_constants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_var_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_var_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m outs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_tokens:\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:1179\u001b[0m, in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1175\u001b[0m   axis_size_env \u001b[38;5;241m=\u001b[39m {d: read(d)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1176\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m avals_in \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mDShapedArray\n\u001b[1;32m   1177\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m a\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(d) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mVar}\n\u001b[1;32m   1178\u001b[0m   rule_ctx \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mreplace(axis_size_env\u001b[38;5;241m=\u001b[39maxis_size_env)\n\u001b[0;32m-> 1179\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrule_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_unwrap_singleton_ir_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effects:\n\u001b[1;32m   1182\u001b[0m   \u001b[38;5;66;03m# If there were ordered effects in the primitive, there should be output\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m   \u001b[38;5;66;03m# tokens we need for subsequent ordered effects.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m   tokens_out \u001b[38;5;241m=\u001b[39m rule_ctx\u001b[38;5;241m.\u001b[39mtokens_out\n",
      "File \u001b[0;32m~/projects/python_venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:3837\u001b[0m, in \u001b[0;36m_unary_reduce_lower\u001b[0;34m(reducer, unit_factory, ctx, x, axes)\u001b[0m\n\u001b[1;32m   3835\u001b[0m aval_out, \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mavals_out\n\u001b[1;32m   3836\u001b[0m dtype \u001b[38;5;241m=\u001b[39m aval_out\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m-> 3837\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mhlo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceOp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval_to_ir_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mir_constants\u001b[49m\u001b[43m(\u001b[49m\u001b[43munit_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43maval_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_int_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3840\u001b[0m scalar_type \u001b[38;5;241m=\u001b[39m mlir\u001b[38;5;241m.\u001b[39maval_to_ir_type(core\u001b[38;5;241m.\u001b[39mShapedArray((), dtype))\n\u001b[1;32m   3841\u001b[0m reducer_region \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mregions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblocks\u001b[38;5;241m.\u001b[39mappend(scalar_type, scalar_type)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 300\n",
    "for ep in range(epochs):\n",
    "    ep_loss = []\n",
    "    for i, batch in enumerate(iter(train_dl)):\n",
    "        batch = jnp.array(batch)\n",
    "#         print(jnp.linalg.norm(batch, axis=1))\n",
    "        batch = jnp.divide(batch, jnp.expand_dims(jnp.linalg.norm(batch, axis=1), axis=1) + 1e-5)\n",
    "#         print(jnp.linalg.norm(batch, axis=1))\n",
    "        train_state = train_step(train_state, batch)\n",
    "        train_state = compute_metrics(state=train_state, batch=batch)\n",
    "        metrics = train_state.metrics.compute()['loss']\n",
    "        ep_loss.append(metrics)\n",
    "    \n",
    "    print(f'Epoch: {ep} Iter {i} Metrics: {jnp.mean(np.array(ep_loss))}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_HR_jax(state, train_loader, test_loader, top_n=10):\n",
    "\n",
    "    counter, hits = 0, 0\n",
    "    r = []\n",
    "    for i, (batch_train, batch_val) in enumerate(zip(iter(train_loader), iter(test_loader))):\n",
    "        batch_train, batch_val = jnp.array(batch_train), jnp.array(batch_val)\n",
    "        delta = batch_val - batch_train\n",
    "        x_rec = state.apply_fn({'params': state.params}, batch_train)\n",
    "        \n",
    "        for k in range(delta.shape[0]):\n",
    "            non_zero_ind = np.nonzero(np.array(delta[k]))[0]\n",
    "            if len(non_zero_ind) > 0:\n",
    "                counter += 1\n",
    "                diff = set([int(item) for item  in np.argpartition(np.array(x_rec[k]).reshape(-1), -top_n)[-top_n:]]) - (set([int(item) for item in non_zero_ind]))\n",
    "                \n",
    "                if len(diff) < top_n:\n",
    "                    hits += 1\n",
    "    return hits / counter\n",
    "\n",
    "def get_recall_jax(state, train_loader, test_loader, top_n=50):\n",
    "\n",
    "    counter, hits = 0, 0\n",
    "    r = []\n",
    "    for i, (batch_train, batch_val) in enumerate(zip(iter(train_loader), iter(test_loader))):\n",
    "        batch_train, batch_val = jnp.array(batch_train), jnp.array(batch_val)\n",
    "        delta = batch_val - batch_train\n",
    "        \n",
    "        x_rec = state.apply_fn({'params': state.params}, batch_train)\n",
    "        \n",
    "        for k in range(delta.shape[0]):\n",
    "            non_zero_ind = np.nonzero(np.array(delta[k]))[0]\n",
    "            if len(non_zero_ind) > 0:\n",
    "                counter += 1\n",
    "                diff = set([int(item) for item in  np.argpartition(np.array(x_rec[k]).reshape(-1), -top_n)[-top_n:]]).intersection(set([int(item) for item in non_zero_ind]))\n",
    "                r.append(len(diff) / len(non_zero_ind))\n",
    "                if len(diff) < top_n:\n",
    "                    hits += 1\n",
    "    return np.mean(r)\n",
    "        \n",
    "get_recall_jax(train_state, train_dl, test_dl)\n",
    "\n",
    "print(f'R@50: {get_recall_jax(train_state, train_dl, test_dl)} HR@10: {get_HR_jax(train_state, train_dl, test_dl, top_n=10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
